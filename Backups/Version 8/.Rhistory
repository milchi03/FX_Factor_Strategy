colnames(data.timestamp)[4] <- "characteristic"
if(weighting_function == "demeaned_relative_signal"){
mean = mean(data.timestamp$characteristic)
data.timestamp$demeaned_characteristic <- data.timestamp$characteristic - mean
# Assign weights proportionally to the absolute values within each group
positive_values <- data.timestamp$demeaned_characteristic[data.timestamp$demeaned_characteristic > 0]
negative_values <- data.timestamp$demeaned_characteristic[data.timestamp$demeaned_characteristic < 0]
data.timestamp$weight <- ifelse(
data.timestamp$demeaned_characteristic > 0,
data.timestamp$demeaned_characteristic / sum(positive_values, na.rm = TRUE),
ifelse(
data.timestamp$demeaned_characteristic < 0,
data.timestamp$demeaned_characteristic / abs(sum(negative_values, na.rm = TRUE)),
0
)
)
data.timestamp$demeaned_characteristic <- NULL
}
if(weighting_function == "demeaned_relative_rank"){
data.timestamp$rank <- rank(data.timestamp$characteristic, ties.method = "average")
n <- nrow(data.timestamp)
#linear function to produce relative ranks (similar to other methods but relative ranks not signal)
data.timestamp$weight <- 8/n^2 * data.timestamp$rank - 4*(n+1)/n^2
data.timestamp$rank <- NULL
}
if (weighting_function == "top_bottom_1_over_num") {
if (is.null(num)) stop("Specify 'num' parameter!")
#sort
data.timestamp <- data.timestamp %>%
arrange(desc(characteristic))
#initialize weights
data.timestamp$weight <- 0
# Assign weights to the top and bottom 'num' rows
data.timestamp$weight[1:num] <- 1 / num
data.timestamp$weight[(nrow(data.timestamp) - num + 1):nrow(data.timestamp)] <- -1 / num
}
return(data.timestamp)
}
#wtf, for carry i = 144, i = 60 return crazy results
# and for Mom_3m i = 177
single_factor <- function(fx_factor){
#inititalize
weighted_returns <- data.frame(date = unique(fx_factor$date),
log_return = NA)
#loop through dates
for(i in 1:length(weighted_returns$date)){
weighted_subset <- weighting(
fx_factor %>% filter(date == weighted_returns$date[i]),
weighting_function = "demeaned_relative_rank"
) #choose from demeaned_relative_signal and demeaned_relative_rank
log_return = sum(weighted_subset$log_return * weighted_subset$weight)
weighted_returns$log_return[i] <- log_return
}
weighted_returns$cum_log_return <- cumsum(weighted_returns$log_return)
return(weighted_returns)
}
#load libraries
library(dplyr) #general use
library(ggplot2) #plots
library(tidyr)
#Debug T = on/ F = off
DEBUG <- FALSE
#load data sets.
fx_factors <- get(load("Data/fx_factors.RData"))
risk_free_rate <- get(load("Data/RF_EUR.RData"))
#tmp fixes
rm(RF_USD)
fx_factors$REER_minus_100 <- NULL
#display df
head(fx_factors %>% arrange(sample(n())), 20)
detect_outliers <- function(x) {
q1 <- quantile(x, 0.25, na.rm = TRUE)
q3 <- quantile(x, 0.75, na.rm = TRUE)
iqr <- q3 - q1
lower_bound <- q1 - 1.5 * iqr
upper_bound <- q3 + 1.5 * iqr
x < lower_bound | x > upper_bound
}
fx_factors %>%
select_if(is.numeric) %>%
summarise(across(everything(), ~ sum(detect_outliers(.))))
weighting <- function(data.timestamp, weighting_function){
colnames(data.timestamp)[4] <- "characteristic"
if(weighting_function == "demeaned_relative_signal"){
mean = mean(data.timestamp$characteristic)
data.timestamp$demeaned_characteristic <- data.timestamp$characteristic - mean
# Assign weights proportionally to the absolute values within each group
positive_values <- data.timestamp$demeaned_characteristic[data.timestamp$demeaned_characteristic > 0]
negative_values <- data.timestamp$demeaned_characteristic[data.timestamp$demeaned_characteristic < 0]
data.timestamp$weight <- ifelse(
data.timestamp$demeaned_characteristic > 0,
data.timestamp$demeaned_characteristic / sum(positive_values, na.rm = TRUE),
ifelse(
data.timestamp$demeaned_characteristic < 0,
data.timestamp$demeaned_characteristic / abs(sum(negative_values, na.rm = TRUE)),
0
)
)
data.timestamp$demeaned_characteristic <- NULL
}
if(weighting_function == "demeaned_relative_rank"){
data.timestamp$rank <- rank(data.timestamp$characteristic, ties.method = "average")
n <- nrow(data.timestamp)
#linear function to produce relative ranks (similar to other methods but relative ranks not signal)
data.timestamp$weight <- 8/n^2 * data.timestamp$rank - 4*(n+1)/n^2
data.timestamp$rank <- NULL
}
if (weighting_function == "top_bottom_1_over_num") {
if (is.null(num)) stop("Specify 'num' parameter!")
#sort
data.timestamp <- data.timestamp %>%
arrange(desc(characteristic))
#initialize weights
data.timestamp$weight <- 0
# Assign weights to the top and bottom 'num' rows
data.timestamp$weight[1:num] <- 1 / num
data.timestamp$weight[(nrow(data.timestamp) - num + 1):nrow(data.timestamp)] <- -1 / num
}
return(data.timestamp)
}
#wtf, for carry i = 144, i = 60 return crazy results
# and for Mom_3m i = 177
single_factor <- function(fx_factor){
#inititalize
weighted_returns <- data.frame(date = unique(fx_factor$date),
log_return = NA)
#loop through dates
for(i in 1:length(weighted_returns$date)){
weighted_subset <- weighting(
fx_factor %>% filter(date == weighted_returns$date[i]),
weighting_function = "demeaned_relative_rank"
) #choose from demeaned_relative_signal and demeaned_relative_rank
log_return = sum(weighted_subset$log_return * weighted_subset$weight)
weighted_returns$log_return[i] <- log_return
}
weighted_returns$cum_log_return <- cumsum(weighted_returns$log_return)
return(weighted_returns)
}
factor_portfolios <- data.frame(date = unique(fx_factors$date))
for(i in 4:ncol(fx_factors)){
factor_portfolio <- single_factor(fx_factor = fx_factors[,c(1:3,i)])
colnames(factor_portfolio)[2] <- colnames(fx_factors)[i]
colnames(factor_portfolio)[3] <- paste0(colnames(fx_factors)[i],".cum")
factor_portfolios <- left_join(x = factor_portfolios,
y = factor_portfolio,
by = "date")
}
rm(factor_portfolio, i)
#we use these for convenience
fac_port_single <- factor_portfolios %>%
select(date, everything(), -matches("\\.cum$")) %>%
pivot_longer(cols = -date, names_to = "Factor", values_to = "LogReturn")
fac_port_cum <- factor_portfolios %>%
select(date, matches("\\.cum$")) %>%
pivot_longer(cols = -date, names_to = "Factor", values_to = "CumLogReturn")
ggplot(fac_port_cum %>% filter(Factor != "REER_minus_100.cum"), aes(x = date, y = CumLogReturn, color = Factor)) +
geom_line() +
labs(
title = "Cumulative Log Returns",
x = "Date",
y = "Cumulative Log Return",
color = "Factor"
) +
theme_minimal()
View(fx_factors)
diagnostic_plot <- function(currency, lm){
# Set up PNG output
png(filename = paste0("regression_diagnostics_", currency, ".png"), width = 2400, height = 1600)
# Adjust layout for 2x3 grid (4 diagnostic plots + summary text)
par(mfrow = c(2, 3), mar = c(4, 4, 2, 1)) # 2 rows, 3 columns, adjust margins
# Plot diagnostic plots (Residuals, Q-Q, Scale-Location, Cook's Distance)
plot(reduced_model, which = 1) # 1: Residuals vs Fitted
plot(reduced_model, which = 2) # 2: Normal Q-Q
plot(reduced_model, which = 3) # 3: Scale-Location
plot(reduced_model, which = 4) # 4: Cook's Distance
# Add model summary as a text plot
summary_text <- capture.output(summary(reduced_model)) # Capture summary output as text
plot.new()                                             # Start a new plot
title(main = currency)                                 # Add heading with currency name
text(0, 1, paste(summary_text, collapse = "\n"), adj = 0, cex = 2) # Add summary
# Close PNG device
dev.off()
cat("Saved diagnostic plots and summary for", currency, "to PNG.\n")
}
training_data <- factor_portfolios %>%
filter(date <= as.Date("2018-06-29")) %>%
select(date, everything(), -matches("\\.cum$"))
testing_data <- factor_portfolios %>% filter(date > as.Date("2018-06-29"))
for(i in 1:length(unique(fx_factors$Currency))){
merged_data <- inner_join(x = training_data,
y = fx_factors %>%
filter(Currency == unique(fx_factors$Currency)[i]) %>%
select("date", "log_return"),
by = "date")
#use stepwise AIC for feature selection
full_model <- lm(log_return ~ ., data = merged_data %>% select(-date))
reduced_model <- MASS::stepAIC(full_model, direction = "both", trace = FALSE)
#diagnostic_plot(unique(fx_factors$Currency)[i], reduced_model)
}
View(merged_data)
diagnostic_plot(unique(fx_factors$Currency)[i], reduced_model)
View(reduced_model)
View(merged_data)
plot(reduced_model)
AIC_currency_specific_models <- list(1:length(unique(fx_factors$Currency)))
View(AIC_currency_specific_models)
?list
AIC_currency_specific_models <- list()
AIC_currency_specific_models <- list(1,2,3)
AIC_currency_specific_models <- list(unlist(1:3))
AIC_currency_specific_models <- list(unique(1:3))
AIC_currency_specific_models <- list()
training_data <- factor_portfolios %>%
filter(date <= as.Date("2018-06-29")) %>%
select(date, everything(), -matches("\\.cum$"))
testing_data <- factor_portfolios %>% filter(date > as.Date("2018-06-29"))
AIC_currency_specific_models <- list()
for(i in 1:length(unique(fx_factors$Currency))){
merged_data <- inner_join(x = training_data,
y = fx_factors %>%
filter(Currency == unique(fx_factors$Currency)[i]) %>%
select("date", "log_return"),
by = "date")
#use stepwise AIC for feature selection
full_model <- lm(log_return ~ ., data = merged_data %>% select(-date))
reduced_model <- MASS::stepAIC(full_model, direction = "both", trace = FALSE)
AIC_currency_specific_models[[unique(fx_factors$Currency)[i]]] <- reduced_model
diagnostic_plot(unique(fx_factors$Currency)[i], reduced_model)
}
training_data <- factor_portfolios %>%
filter(date <= as.Date("2018-06-29")) %>%
select(date, everything(), -matches("\\.cum$"))
testing_data <- factor_portfolios %>% filter(date > as.Date("2018-06-29"))
AIC_currency_specific_models <- list()
for(i in 1:length(unique(fx_factors$Currency))){
merged_data <- inner_join(x = training_data,
y = fx_factors %>%
filter(Currency == unique(fx_factors$Currency)[i]) %>%
select("date", "log_return"),
by = "date")
#use stepwise AIC for feature selection
full_model <- lm(log_return ~ ., data = merged_data %>% select(-date))
reduced_model <- MASS::stepAIC(full_model, direction = "both", trace = FALSE)
AIC_currency_specific_models[[unique(fx_factors$Currency)[i]]] <- reduced_model
#diagnostic_plot(unique(fx_factors$Currency)[i], reduced_model)
}
View(AIC_currency_specific_models)
# Initialize a list to store predictions for each currency
currency_predictions <- list()
# Iterate over the unique currencies
for (i in 1:length(unique(fx_factors$Currency))) {
current_currency <- unique(fx_factors$Currency)[i]
# Retrieve the model for the current currency
current_model <- AIC_currency_specific_models[[current_currency]]
# Merge testing data with fx_factors for the current currency
merged_test_data <- inner_join(
x = testing_data,
y = fx_factors %>%
filter(Currency == current_currency) %>%
select("date", "log_return"),
by = "date"
)
# Ensure the predictors in the test set match those used in the model
test_features <- merged_test_data %>%
select(all_of(names(current_model$coefficients)[-1]))  # Exclude intercept
# Make predictions using the model
predictions <- predict(current_model, newdata = test_features)
# Store predictions with their corresponding dates
currency_predictions[[current_currency]] <- data.frame(
date = merged_test_data$date,
predicted_log_return = predictions
)
}
# Combine all predictions into one data frame (optional)
all_predictions <- bind_rows(
lapply(names(currency_predictions), function(currency) {
currency_predictions[[currency]] %>%
mutate(Currency = currency)
})
)
# View predictions
head(all_predictions)
View(all_predictions)
str(all_predictions)
# Initialize a list to store predictions for each currency
currency_predictions <- list()
# Iterate over the unique currencies
for (i in 1:length(unique(fx_factors$Currency))) {
current_currency <- unique(fx_factors$Currency)[i]
# Retrieve the model for the current currency
current_model <- AIC_currency_specific_models[[current_currency]]
# Merge testing data with fx_factors for the current currency
merged_test_data <- inner_join(
x = testing_data,
y = fx_factors %>%
filter(Currency == current_currency) %>%
select("date", "log_return"),
by = "date"
)
# Ensure the predictors in the test set match those used in the model
test_features <- merged_test_data %>%
select(all_of(names(current_model$coefficients)[-1]))  # Exclude intercept
# Make predictions using the model
predictions <- predict(current_model, newdata = test_features)
# Store predictions with their corresponding dates
currency_predictions[[current_currency]] <- data.frame(
date = merged_test_data$date,
predicted_log_return = predictions
)
}
# Combine all predictions into one data frame with clean row indices
all_predictions <- bind_rows(
lapply(names(currency_predictions), function(currency) {
currency_predictions[[currency]] %>%
mutate(Currency = currency)  # Add currency identifier
}),
.id = "source"  # Optional: source column to keep track of currency if needed
) %>%
select(-source)  # Remove the temporary 'source' column if not needed
# Reset row names
rownames(all_predictions) <- NULL
# View the cleaned predictions
head(all_predictions)
View(all_predictions)
View(testing_data)
View(training_data)
View(test_features)
View(merged_test_data)
View(fx_factors)
str(fx_factors)
final_data <- fx_factors %>%
left_join(all_predictions, by = c("date", "Currency"))
# View the resulting data
head(final_data)
final_data <- fx_factors %>%
select(date, Currency, log_return) %>%
left_join(all_predictions, by = c("date", "Currency"))
# View the resulting data
head(final_data)
final_data <- fx_factors %>%
select(date, Currency, log_return) %>%
filter(date > as.Date("2018-06-29")) %>%
left_join(all_predictions, by = c("date", "Currency"))
# View the resulting data
head(final_data)
na.omit(final_data)
na.omit(final_data)
# View the resulting data
head(final_data)
# View the resulting data
final_data
final_data <- fx_factors %>%
select(date, Currency, log_return) %>%
filter(date > as.Date("2018-06-29")) %>%
left_join(all_predictions, by = c("date", "Currency")) %>%
mutate(Prediction_Error = predicted_log_return - log_return)
# View the resulting data
final_data
final_data <- fx_factors %>%
select(date, Currency, log_return) %>%
filter(date > as.Date("2018-06-29")) %>%
left_join(all_predictions, by = c("date", "Currency")) %>%
mutate(Prediction_Error = log_return - predicted_log_return)
# View the resulting data
final_data
# View the resulting data
head(final_data,50)
hist(final_data$Prediction_Error)
tail(final_data,50)
final_data <- fx_factors %>%
select(date, Currency, log_return) %>%
filter(date > as.Date("2018-06-29")) %>%
left_join(all_predictions, by = c("date", "Currency")) %>%
mutate(Prediction_Error = log_return - predicted_log_return) %>%
sort(date)
final_data <- fx_factors %>%
select(date, Currency, log_return) %>%
filter(date > as.Date("2018-06-29")) %>%
left_join(all_predictions, by = c("date", "Currency")) %>%
mutate(Prediction_Error = log_return - predicted_log_return) %>%
arrange(desc(date))
# View the resulting data
head(final_data,50)
final_final_data <- final_data %>%
group_by(date) %>%  # Group by each date
slice_max(order_by = predicted_log_return, n = 2, with_ties = FALSE) %>%  # Select top 2 rows
ungroup()  # Ungroup after the operation
head(final_final_data,50)
final_final_data <- final_data %>%
group_by(date) %>%  # Group by each date
slice_max(order_by = predicted_log_return, n = 2, with_ties = FALSE) %>%  # Select top 2 rows
ungroup() %>% # Ungroup after the operation
arrange(desc(date))
head(final_final_data,50)
final_data <- fx_factors %>%
select(date, Currency, log_return) %>%
filter(date > as.Date("2018-06-29")) %>%
left_join(all_predictions, by = c("date", "Currency")) %>%
mutate(abs_prediction_error = log_return - predicted_log_return,
rel_prediction_error = log_return / predicted_log_return - 1) %>%
arrange(desc(date))
# View the resulting data
head(final_data,50)
final_final_data <- final_data %>%
group_by(date) %>%  # Group by each date
slice_max(order_by = predicted_log_return, n = 2, with_ties = FALSE) %>%  # Select top 2 rows
ungroup() %>% # Ungroup after the operation
arrange(desc(date))
head(final_final_data,50)
plot(final_final_data)
plot(final_final_data$log_return)
plot(cumsum(final_final_data$log_return))
plot(cumsum(final_final_data$log_return), type = "l")
library(ggplot2)
# Summarize log_return by date
summed_returns <- final_final_data %>%
group_by(date) %>%
summarize(summed_log_return = sum(log_return, na.rm = TRUE))  # Sum log returns per date
# Create the line plot
ggplot(summed_returns, aes(x = date, y = summed_log_return)) +
geom_line(color = "blue", size = 1) +
labs(
title = "Summed Log Returns Over Time",
x = "Date",
y = "Summed Log Return"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
axis.text.x = element_text(angle = 45, hjust = 1)
)
# Summarize log_return by date
summed_returns <- final_final_data %>%
group_by(date) %>%
summarize(summed_log_return = sum(log_return, na.rm = TRUE))  # Sum log returns per date
# Create the line plot
ggplot(summed_returns, aes(x = date, y = summed_log_return)) +
geom_line(color = "blue", linewidth = 1) +  # Use linewidth instead of size
labs(
title = "Summed Log Returns Over Time",
x = "Date",
y = "Summed Log Return"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
axis.text.x = element_text(angle = 45, hjust = 1)
)
# Compute cumulative log returns by date
cumulative_returns <- final_final_data %>%
group_by(date) %>%
summarize(summed_log_return = sum(log_return, na.rm = TRUE)) %>%  # Sum log returns per date
mutate(cumulative_log_return = cumsum(summed_log_return))  # Calculate cumulative sum
# Create the cumulative log returns line plot
ggplot(cumulative_returns, aes(x = date, y = cumulative_log_return)) +
geom_line(color = "blue", linewidth = 1) +  # Use linewidth for line thickness
labs(
title = "Cumulative Log Returns Over Time",
x = "Date",
y = "Cumulative Log Return"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
axis.text.x = element_text(angle = 45, hjust = 1)
)
# Compute cumulative log returns by date
cumulative_returns <- final_final_data %>%
group_by(date) %>%
summarize(summed_log_return = sum(log_return, na.rm = TRUE)) %>%  # Sum log returns per date
mutate(cumulative_log_return = cumsum(summed_log_return))  # Calculate cumulative sum
# Create the cumulative log returns line plot
ggplot(cumulative_returns, aes(x = date, y = cumulative_log_return)) +
geom_line(color = "blue", linewidth = 1) +  # Use linewidth for line thickness
scale_x_date(
breaks = c(min(cumulative_returns$date), max(cumulative_returns$date)),  # Start and end dates
labels = scales::date_format("%Y-%m-%d")  # Format dates as "YYYY-MM-DD"
) +
labs(
title = "Cumulative Log Returns Over Time",
x = "Date",
y = "Cumulative Log Return"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
axis.text.x = element_text(angle = 45, hjust = 1)
)
# Compute cumulative log returns by date
cumulative_returns <- final_final_data %>%
group_by(date) %>%
summarize(summed_log_return = sum(log_return, na.rm = TRUE)) %>%  # Sum log returns per date
mutate(cumulative_log_return = cumsum(summed_log_return))  # Calculate cumulative sum
# Create the cumulative log returns line plot
ggplot(cumulative_returns, aes(x = date, y = cumulative_log_return)) +
geom_line(color = "blue", linewidth = 1) +  # Use linewidth for line thickness
scale_x_date(
breaks = c(min(cumulative_returns$date), max(cumulative_returns$date)),  # Start and end dates
labels = scales::date_format("%Y-%m-%d")  # Format dates as "YYYY-MM-DD"
) +
labs(
title = "Cumulative Log Returns Over Time",
x = "Date",
y = "Cumulative Log Return"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
axis.text.x = element_text(angle = 45, hjust = 1)
)
View(cumulative_returns)
View(final_final_data)
